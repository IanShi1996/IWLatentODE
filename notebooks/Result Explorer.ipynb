{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Custom lib\n",
    "from model import LatentNeuralODEBuilder\n",
    "from utils import gpu, asnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineSet(Dataset):\n",
    "    def __init__(self, data, time):\n",
    "        self.data = data\n",
    "        self.time = time\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.time\n",
    "    \n",
    "class GenericSet(Dataset):\n",
    "    def __init__(self, data, time):\n",
    "        self.data = data\n",
    "        self.time = time\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_experiment_files(path_dir):\n",
    "    files = [f for f in os.listdir(path_dir) if f[0] != '.']\n",
    "    files = [f.split('_') for f in files]\n",
    "\n",
    "    experiments = {}\n",
    "\n",
    "    for f in files:\n",
    "        dataset = f[0]\n",
    "        exp_key = f[1:2] + f[3:-1]\n",
    "        exp_key = '_'.join(exp_key)\n",
    "\n",
    "        exp_run = f[-1]\n",
    "\n",
    "        if dataset not in experiments:\n",
    "            experiments[dataset] = {}\n",
    "\n",
    "        if exp_key in experiments[dataset]:\n",
    "            experiments[dataset][exp_key].append(exp_run)\n",
    "        else:\n",
    "            experiments[dataset][exp_key] = [exp_run]\n",
    "\n",
    "    return experiments\n",
    "\n",
    "def load_models(experiments, dataset, target, dir_path):\n",
    "    if dataset not in experiments or target not in experiments[dataset]:\n",
    "        raise KeyError()\n",
    "        \n",
    "    runs = experiments[dataset][target]\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for run in runs:\n",
    "        model = target.split('_')[0]\n",
    "        params = '_'.join(target.split('_')[1:])\n",
    "        path = \"{}_{}_lode_{}_{}\".format(dataset, model, params, run)\n",
    "        \n",
    "        model = torch.load(dir_path + '/' + path)\n",
    "        models.append(model)\n",
    "        \n",
    "    return models\n",
    "\n",
    "def load_model_params(model_data, exp_type, inds=None):\n",
    "    \n",
    "    if inds is None:\n",
    "        inds = range(len(model_data))\n",
    "    \n",
    "    elbo_type = exp_type.split('_')[0]\n",
    "\n",
    "    loaded_models = []\n",
    "    \n",
    "    if elbo_type in ['base', 'betavae']:\n",
    "        elbo_type = 'iwae'\n",
    "    \n",
    "    for i in inds:\n",
    "        builder = LatentNeuralODEBuilder(**model_data[i]['model_args'])\n",
    "        model = builder.build_latent_node(elbo_type).to(device)\n",
    "        model.load_state_dict(model_data[i]['model_state_dict'])\n",
    "\n",
    "        loaded_models.append(model)\n",
    "        \n",
    "    return loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'aussign'\n",
    "model_path = '../models'\n",
    "exp_type = 'miwae_3_8'\n",
    "\n",
    "experiments = parse_experiment_files(model_path)\n",
    "model_data = load_models(experiments, dataset, exp_type, model_path)\n",
    "\n",
    "# Load Data\n",
    "if dataset == 'sine':\n",
    "    generator = torch.load('../' + model_data[0]['data_path'])['generator']\n",
    "    test_time, test_data = generator.get_test_set()\n",
    "    test_data = test_data.reshape(len(test_data), -1, 1)\n",
    "\n",
    "    test_data_tt = gpu(test_data)\n",
    "    test_time_tt = gpu(test_time)\n",
    "\n",
    "    test_dataset = SineSet(test_data_tt, test_time_tt)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = len(test_dataset))\n",
    "\n",
    "else:\n",
    "    data = torch.load('../' + model_data[0]['data_path'])\n",
    "\n",
    "    test_data = data['test_dataset']\n",
    "\n",
    "    test_time = list(range(test_data.shape[1]))\n",
    "    \n",
    "    test_data_tt = gpu(test_data)\n",
    "    test_time_tt = gpu(test_time)\n",
    "\n",
    "    test_dataset = SineSet(test_data_tt, test_time_tt)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(exp_type, loaded_models, data, time, args):\n",
    "    elbo_type = exp_type.split('_')[0]\n",
    "\n",
    "    if elbo_type in ['base', 'betavae']:\n",
    "        elbo_type = 'iwae'\n",
    "\n",
    "    mses = []\n",
    "    elbos = []\n",
    "\n",
    "    for model in loaded_models:\n",
    "        out = model.forward(data, time, args)\n",
    "        elbo = model.get_elbo(data, *out, args)\n",
    "\n",
    "        if elbo_type in ['miwae', 'ciwae']:\n",
    "            pred_x = torch.mean(torch.mean(out[0], 2), 1)\n",
    "        elif elbo_type == 'iwae':\n",
    "            pred_x = torch.mean(out[0], 1)\n",
    "        elif elbo_type == 'piwae':\n",
    "            pred_x = out[0].view(data.shape[0], args['M'], args['K'], data.shape[1], data.shape[2])\n",
    "            pred_x = torch.mean(torch.mean(pred_x, 1), 1)\n",
    "            \n",
    "            elbo = (elbo[0] + elbo[0]) / 2\n",
    "        else:\n",
    "            pred_x = out[0]\n",
    "        \n",
    "        mse = nn.MSELoss()(data, pred_x)\n",
    "        \n",
    "        elbos.append(elbo.item())\n",
    "        mses.append(mse.item())\n",
    "\n",
    "    return mses, elbos\n",
    "\n",
    "def get_loss_batch(exp_type, loaded_models, data, time, args, batch_size=None):\n",
    "    if batch_size:\n",
    "        data = data.view(batch_size, data.shape[0] // batch_size, *data.shape[1:])\n",
    "        mses = []\n",
    "        elbos = []\n",
    "\n",
    "        for d in tqdm(data):\n",
    "            mse, elbo = get_loss(exp_type, loaded_models, d, time, args)\n",
    "            mses.append(mse)\n",
    "            elbos.append(elbo)\n",
    "        \n",
    "        # This is ok since our subsamples are same size.\n",
    "        return np.mean(mses, axis=0), np.mean(elbos, axis=0)\n",
    "\n",
    "    else:\n",
    "        return get_loss(exp_type, loaded_models, data, time, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_losses(experiments, dataset, model_path, data, time):\n",
    "    losses = {}\n",
    "\n",
    "    for exp in tqdm(experiments[dataset]):\n",
    "        model_data = load_models(experiments, dataset, exp, model_path)\n",
    "        loaded_models = load_model_params(model_data, exp)\n",
    "        train_args = model_data[0]['train_args']\n",
    "        \n",
    "        train_args['M'] = 1\n",
    "        train_args['K'] = 250\n",
    "        train_args['beta'] = 0\n",
    "        mses, elbos = get_loss_batch(exp, loaded_models, data, time, train_args, None)\n",
    "\n",
    "        del loaded_models\n",
    "        del model_data\n",
    "        \n",
    "        losses[exp] = [mses, elbos]\n",
    "    return losses\n",
    "\n",
    "losses = compute_losses(experiments, dataset, model_path, test_data_tt, test_time_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = 'base_1_1'\n",
    "best_mses = losses[best_model][0]\n",
    "best_elbos = losses[best_model][1]\n",
    "\n",
    "sorted_losses = dict(sorted(losses.items(), key=lambda item: np.mean(item[1][0])))\n",
    "\n",
    "for exp_type, (mses, elbos) in sorted_losses.items():\n",
    "    mses = [m for m in mses if m < 3]\n",
    "    print('Experiment: {}'.format(exp_type))\n",
    "    print(\"MSE: {:.4f}±{:.4f}\".format(np.mean(mses), np.std(mses)))\n",
    "    print(\"log p(x): {:.2f}±{:.2f}\".format(np.mean(elbos), np.std(elbos)))\n",
    "\n",
    "    p_val_elbo = stats.ttest_ind(best_elbos, elbos).pvalue\n",
    "    p_val_mse = stats.ttest_ind(best_mses, mses).pvalue\n",
    "    print('mse p-value vs best: {}'.format(p_val_mse))\n",
    "    print('log p(x) p-value vs best: {}'.format(p_val_elbo))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_times(experiments, dataset):\n",
    "    runtimes = {}\n",
    "\n",
    "    for exp in experiments[dataset]:\n",
    "        model_data = load_models(experiments, dataset, exp, model_path)\n",
    "        rts = []\n",
    "        for d in model_data:\n",
    "            rts.append(np.mean(d['train_obj'].runtimes))\n",
    "        \n",
    "        runtimes[exp] = np.mean(rts)\n",
    "\n",
    "    sorted_runtimes = dict(sorted(runtimes.items(), key=lambda item: item[1]))\n",
    "    for k, v in sorted_runtimes.items():\n",
    "        print(\"Exp: {} Avg Epoch Time: {}\".format(k, v))\n",
    "    \n",
    "    return sorted_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runtimes = get_train_times(experiments, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "def plot_val_loss(ax, data, title, trunc_l=0, trunc_r=400):\n",
    "    loss_hists = [d['train_obj'].val_loss_hist[trunc_l:trunc_r] for d in data]\n",
    "    \n",
    "    avg_loss_hist = [moving_average(np.array(h), 15) for h in loss_hists]\n",
    "    \n",
    "    mean_val = np.mean(avg_loss_hist, 0)\n",
    "    std_val = np.std(avg_loss_hist, 0)\n",
    "\n",
    "    time = range(len(avg_loss_hist[0]))\n",
    "\n",
    "    if title == 'base_1_1':\n",
    "        ax.plot(time, mean_val, label=title, c='k', lw=3)\n",
    "    else:\n",
    "        ax.plot(time, mean_val, label=title)\n",
    "\n",
    "    \n",
    "    ax.fill_between(time, mean_val + std_val, mean_val - std_val, alpha=0.2)\n",
    "    #ax.fill_between(time, np.min(avg_loss_hist, axis=0), np.max(avg_loss_hist, axis=0), alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_models = ['miwae_3_8', 'base_1_1', 'iwae_1_5', 'iwae_1_25', 'piwae_3_8', 'ciwae_6_4_0.5']\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "for exp in target_models:\n",
    "    data = load_models(experiments, dataset, exp, model_path)\n",
    "    plot_val_loss(ax[0], data, exp)\n",
    "\n",
    "    plot_val_loss(ax[1], data, exp)\n",
    "\n",
    "ax[0].set_xlim(0, 150)\n",
    "ax[0].legend(loc='right')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('- ELBO')\n",
    "\n",
    "ax[1].set_ylim(-400, 1000)\n",
    "ax[1].set_xlim(150, 375)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('- ELBO')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'aussign'\n",
    "model_path = '../models'\n",
    "exp_type = 'iwae_1_5'\n",
    "\n",
    "experiments = parse_experiment_files(model_path)\n",
    "model_data = load_models(experiments, dataset, exp_type, model_path)\n",
    "\n",
    "loaded_models = load_model_params(model_data, exp_type)\n",
    "model = loaded_models[1]\n",
    "args = model_data[0]['train_args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.sort(np.random.uniform(0, 7, 200))\n",
    "tp = np.linspace(0, 7, 200)\n",
    "s1 = torch.Tensor(np.sin(tp * 3) * 5)\n",
    "s2 = torch.Tensor(np.sin(tp * 3) * -1)\n",
    "plt.plot(tp, s1)\n",
    "plt.plot(tp, s2)\n",
    "plt.plot(tp, s1+s2, ls='--')\n",
    "\n",
    "data_1 = s1.view(-1, 1).to(device)\n",
    "data_2 = s2.view(-1, 1).to(device)\n",
    "tp = torch.Tensor(tp).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = test_data_tt[0]\n",
    "data_2 = test_data_tt[25]\n",
    "tp = test_time_tt\n",
    "\n",
    "plt.plot(asnp(test_time_tt), asnp(data_1))\n",
    "plt.plot(asnp(test_time_tt), asnp(data_2))\n",
    "\n",
    "plt.plot(asnp(test_time_tt), asnp(data_2 + data_1), ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = model.forward(data_1.unsqueeze(0), tp, args)\n",
    "out2 = model.forward(data_2.unsqueeze(0), tp, args)\n",
    "\n",
    "z0_1 = torch.mean(out1[1], 1)\n",
    "z0_2 = torch.mean(out2[1], 1)\n",
    "\n",
    "# Latent arithmetic\n",
    "z0_comb = z0_1 + z0_2\n",
    "z0_comb = torch.mean(z0_comb, 1)\n",
    "\n",
    "# Mean vector\n",
    "z0_comb = torch.mean(torch.cat([z0_1, z0_2]), axis=0)\n",
    "\n",
    "pred_z = model.generate_from_latent(z0_comb, tp, args['model_rtol'],\n",
    "                                    args['model_atol'], args['method'])\n",
    "pred_x = model.dec(pred_z)\n",
    "\n",
    "plt.plot(asnp(tp), asnp(pred_x[0]))\n",
    "plt.plot(asnp(tp), s1+s2, ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 120\n",
    "out_1 = model.forward(test_data_tt[ind].unsqueeze(0), test_time_tt, args)\n",
    "\n",
    "\n",
    "out = torch.mean(torch.mean(out_1[0], 1), 1)\n",
    "out = torch.mean(out_1[0], 1)\n",
    "\n",
    "d_ind = 2\n",
    "plt.plot(asnp(test_time_tt), asnp(out)[0][:, d_ind], ls='--')\n",
    "plt.plot(asnp(test_time_tt), asnp(test_data_tt[ind])[:, d_ind])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
